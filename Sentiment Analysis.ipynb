{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ba8188d-b05e-43b4-b1cd-f15a323e9094",
   "metadata": {},
   "source": [
    "# import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd58dbc-4348-4cdb-97a2-7db6429621fe",
   "metadata": {},
   "source": [
    "# Step 1: Load the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a21bfba-5dab-4e1d-92be-87668c05c895",
   "metadata": {},
   "source": [
    "# Step 3: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89c408b-2ab0-4601-a17d-0595b7a0deb8",
   "metadata": {},
   "source": [
    "# Step 4: Generate Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbb8fda-aaef-4a4b-8799-2d8d5f31dbf4",
   "metadata": {},
   "source": [
    "# Step 5: Indexing with FAISS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e26949a-5f61-404b-a613-86a3878589d2",
   "metadata": {},
   "source": [
    "# Step 6: Query Input\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0f7283-1cda-4e80-b41c-0cf4919e7665",
   "metadata": {},
   "source": [
    "# Step 7: Sentiment Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36593ab6-68a5-4e5d-b537-4acf4a6a1113",
   "metadata": {},
   "source": [
    "# Example of taking user input and responding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf49461-4b67-4ea5-b839-407c6975d514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load Journal Data\n",
    "df = pd.read_csv(r'C:\\Users\\DELL\\OneDrive - UPES\\Desktop\\IIT Kanpur\\data\\data.csv')\n",
    "print(f\"‚úÖ Loaded {len(df)} journal entries.\")\n",
    "\n",
    "if df.empty:\n",
    "    print(\"‚ö† DataFrame is empty. Exiting program.\")\n",
    "    exit()\n",
    "\n",
    "df['date'] = pd.date_range(start='2021-02-12', periods=len(df), freq='D')\n",
    "\n",
    "# Load Models\n",
    "sentiment_pipeline = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\")\n",
    "print(\"‚úÖ Sentiment Analysis model loaded successfully!\")\n",
    "\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "print(\"‚úÖ Sentence Transformer model loaded successfully!\")\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "llm = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\")\n",
    "print(\"‚úÖ BART model loaded successfully!\")\n",
    "\n",
    "print(\"‚úÖ LLM loaded successfully for text generation!\")\n",
    "\n",
    "# Clean Text Function\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', str(text))\n",
    "    return text.lower()\n",
    "\n",
    "df['cleaned_text'] = df['Answer'].fillna(\"\").apply(clean_text)\n",
    "\n",
    "# Create Embeddings and Vector Store\n",
    "embeddings = embedding_model.encode(df['cleaned_text'].tolist(), convert_to_numpy=True)\n",
    "dimension = embeddings.shape[1]\n",
    "faiss_index = faiss.IndexFlatL2(dimension)\n",
    "\n",
    "if len(embeddings) > 0:\n",
    "    faiss_index.add(np.array(embeddings, dtype=np.float32))\n",
    "    print(\"‚úÖ FAISS index populated successfully!\")\n",
    "else:\n",
    "    print(\"‚ö† No embeddings generated. Check input data.\")\n",
    "    exit()\n",
    "\n",
    "# Retrieve Similar Entries\n",
    "def retrieve_similar_entries(query, top_k=3):\n",
    "    if faiss_index.ntotal == 0:\n",
    "        print(\"‚ö† FAISS index is empty! No retrieval possible.\")\n",
    "        return df.head(0)\n",
    "    \n",
    "    query_embedding = embedding_model.encode([query], convert_to_numpy=True)\n",
    "    query_embedding = np.array(query_embedding, dtype=np.float32)\n",
    "    distances, indices = faiss_index.search(query_embedding, top_k)\n",
    "    \n",
    "    return df.iloc[indices[0]] if len(indices) > 0 else df.head(0)\n",
    "\n",
    "# Analyze Sentiment\n",
    "def analyze_sentiment(entry):\n",
    "    return sentiment_pipeline(entry)[0]\n",
    "\n",
    "# Generate AI Reflection\n",
    "\n",
    "def generate_reflection(current_entry, retrieved_entries):\n",
    "    # Extract emotions and key themes\n",
    "    current_emotion = analyze_sentiment(current_entry)  # Assuming you have a function for this\n",
    "    \n",
    "    past_emotions = [analyze_sentiment(entry) for entry in retrieved_entries]\n",
    "    \n",
    "    # Identify common emotional patterns\n",
    "    if all(emotion == \"joy\" for emotion in past_emotions):\n",
    "        trend = \"consistent happiness and accomplishment\"\n",
    "        insight = \"You thrive on achieving goals, and these moments fuel your confidence.\"\n",
    "    elif \"stress\" in past_emotions and \"joy\" in past_emotions:\n",
    "        trend = \"a shift from stress to relief\"\n",
    "        insight = \"You tend to feel stressed before major tasks but ultimately gain confidence from completing them.\"\n",
    "    else:\n",
    "        trend = \"varied emotions\"\n",
    "        insight = \"Your emotions fluctuate based on workload, but accomplishment consistently brings you joy.\"\n",
    "\n",
    "    # Final AI-generated reflection\n",
    "    reflection = (\n",
    "        f\"Lately, you've experienced {trend}. \"\n",
    "        f\"{insight} Keep recognizing your achievements, as they reinforce your sense of progress and capability.\"\n",
    "    )\n",
    "\n",
    "    return reflection\n",
    "\n",
    "\n",
    "# Perform Sentiment Analysis with Enhanced RAG\n",
    "report = \"\\U0001F4DC *Journal Sentiment Analysis Report* \\U0001F4DC\\n\" + \"=\" * 50 + \"\\n\"\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    try:\n",
    "        print(f\"\\n---------------------------------------\\n\")\n",
    "        print(f\"Entry: {row['cleaned_text']}\")  \n",
    "\n",
    "        similar_entries_df = retrieve_similar_entries(row['cleaned_text'])\n",
    "        similar_entries_texts = similar_entries_df['cleaned_text'].tolist()\n",
    "        print(f\"‚úÖ Retrieved {len(similar_entries_texts)} similar entries\")  \n",
    "\n",
    "        current_sentiment = analyze_sentiment(row['cleaned_text'])  \n",
    "        current_emotion = current_sentiment['label']\n",
    "        print(f\"üìä Emotion (Current Entry): {current_emotion}\")  \n",
    "\n",
    "        ai_reflection = generate_reflection(row['cleaned_text'], similar_entries_texts)\n",
    "        print(f\"üß† AI Reflection: {ai_reflection}\")\n",
    "\n",
    "        report += f\"\\U0001F4C5 *Date:* {row['date']}\\n\"\n",
    "        report += f\"‚úç *Entry:* {row['cleaned_text']}\\n\"\n",
    "        report += f\"\\U0001F4CA *Emotion (Current Entry):* {current_emotion}\\n\"\n",
    "        report += f\"\\U0001F50E *Similar Entries Retrieved:* {len(similar_entries_texts)}\\n\"\n",
    "        report += f\"üß† *AI Reflection:* {ai_reflection}\\n\"\n",
    "        report += \"-\" * 50 + \"\\n\"\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing entry {index}: {e}\")\n",
    "\n",
    "# Save Report to File\n",
    "with open(\"sentiment_analysis_report.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(report)\n",
    "\n",
    "print(report)\n",
    "print(\"‚úÖ Sentiment analysis report with RAG and AI-generated reflections successfully generated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4cbb0a-f216-4fd1-aa96-60222d3e9d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 1473 journal entries.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Sentiment Analysis model loaded successfully!\n",
      "‚úÖ Sentence Transformer model loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ FLAN-T5 model loaded successfully!\n",
      "‚úÖ FAISS index populated successfully!\n",
      "\n",
      "---------------------------------------\n",
      "\n",
      "Entry: my family was the most salient part of my day since most days the care of my 2 children occupies the majority of my time they are 2 years old and 7 months and i love them but they also require so much attention that my anxiety is higher than ever i am often overwhelmed by the care the require but at the same i am so excited to see them hit developmental and social milestones\n",
      "‚úÖ Retrieved 3 similar entries\n",
      "üìä Emotion (Current Entry): fear\n",
      "üß† AI Reflection: The user's journal entry: my family was the most salient part of my day since most days the care of my 2 children occupies the majority of my time they are 2 years old and 7 months and i love them but they also require so much attention that my anxiety is higher than ever i am often overwhelmed by the care the require but at the same i am so excited to see them hit developmental and social milestones\n",
      "\n",
      "---------------------------------------\n",
      "\n",
      "Entry: yoga keeps me focused i am able to take some time for me and breath and work my body this is important because it sets up my mood for the whole day\n",
      "‚úÖ Retrieved 3 similar entries\n",
      "üìä Emotion (Current Entry): joy\n",
      "üß† AI Reflection: The user's journal entry: yoga keeps me focused. I am able to take some time for me and breath and work my body this is important because it sets up my mood for the whole day.\n",
      "\n",
      "---------------------------------------\n",
      "\n",
      "Entry: yesterday my family and i played a bunch of board games my husband won most of them which is not surprising in the least we played all sorts of games including life clue mouse trap and more it was relaxing and such a happy fun filled moment\n",
      "‚úÖ Retrieved 3 similar entries\n",
      "üìä Emotion (Current Entry): joy\n",
      "üß† AI Reflection: The user's journal entry: yesterday my family and i played a bunch of board games my husband won most of them which is not surprising in the least we played all sorts of games including life clue mouse trap and more it was relaxing and such a happy fun filled moment\n",
      "\n",
      "---------------------------------------\n",
      "\n",
      "Entry: yesterday i visited my parents and had dinner with them  i hadnt seen them in a few weeks so it was wonderful to see them and catch up on things\n",
      "‚úÖ Retrieved 3 similar entries\n",
      "üìä Emotion (Current Entry): joy\n",
      "üß† AI Reflection: i had a great time with my parents yesterday and it was great to see them again.\n",
      "\n",
      "---------------------------------------\n",
      "\n",
      "Entry: yesterday i really felt the importance of my health i went on a bit longer hike than usual and was very happy that i could do so it really made me appreciate my health with all the news of people dying and the tragedy of the utah family murder in mexico it really made me aware of the importance of my own health and well being\n",
      "‚úÖ Retrieved 3 similar entries\n",
      "üìä Emotion (Current Entry): joy\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import pipeline, AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "# Load Journal Data\n",
    "df = pd.read_csv(r'C:\\Users\\DELL\\OneDrive - UPES\\Desktop\\IIT Kanpur\\data\\data.csv')\n",
    "print(f\"‚úÖ Loaded {len(df)} journal entries.\")\n",
    "\n",
    "if df.empty:\n",
    "    print(\"‚ö† DataFrame is empty. Exiting program.\")\n",
    "    exit()\n",
    "\n",
    "df['date'] = pd.date_range(start='2021-02-12', periods=len(df), freq='D')\n",
    "\n",
    "# Load Models\n",
    "sentiment_pipeline = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\")\n",
    "print(\"‚úÖ Sentiment Analysis model loaded successfully!\")\n",
    "\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "print(\"‚úÖ Sentence Transformer model loaded successfully!\")\n",
    "\n",
    "llm = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\")\n",
    "print(\"‚úÖ FLAN-T5 model loaded successfully!\")\n",
    "\n",
    "# Clean Text Function\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', str(text))\n",
    "    return text.lower()\n",
    "\n",
    "df['cleaned_text'] = df['Answer'].fillna(\"\").apply(clean_text)\n",
    "\n",
    "# Create Embeddings and Vector Store\n",
    "embeddings = embedding_model.encode(df['cleaned_text'].tolist(), convert_to_numpy=True)\n",
    "dimension = embeddings.shape[1]\n",
    "faiss_index = faiss.IndexFlatL2(dimension)\n",
    "\n",
    "if len(embeddings) > 0:\n",
    "    faiss_index.add(np.array(embeddings, dtype=np.float32))\n",
    "    print(\"‚úÖ FAISS index populated successfully!\")\n",
    "else:\n",
    "    print(\"‚ö† No embeddings generated. Check input data.\")\n",
    "    exit()\n",
    "\n",
    "# Retrieve Similar Entries\n",
    "def retrieve_similar_entries(query, top_k=3):\n",
    "    if faiss_index.ntotal == 0:\n",
    "        print(\"‚ö† FAISS index is empty! No retrieval possible.\")\n",
    "        return []\n",
    "    \n",
    "    query_embedding = embedding_model.encode([query], convert_to_numpy=True)\n",
    "    distances, indices = faiss_index.search(query_embedding.astype(np.float32), top_k)\n",
    "    \n",
    "    return df.iloc[indices[0]]['cleaned_text'].tolist() if len(indices) > 0 else []\n",
    "\n",
    "# Analyze Sentiment\n",
    "def analyze_sentiment(entry):\n",
    "    return sentiment_pipeline(entry)[0]['label']\n",
    "\n",
    "# Generate AI Reflection\n",
    "def generate_reflection(current_entry, retrieved_entries):\n",
    "    current_emotion = analyze_sentiment(current_entry)\n",
    "    past_emotions = [analyze_sentiment(entry) for entry in retrieved_entries]\n",
    "    \n",
    "    emotion_counts = {emotion: past_emotions.count(emotion) for emotion in set(past_emotions)}\n",
    "    dominant_emotion = max(emotion_counts, key=emotion_counts.get, default=\"neutral\")\n",
    "    \n",
    "    summary_prompt = (\n",
    "        f\"User's journal entry: {current_entry}\\n\"\n",
    "        f\"Past similar entries and emotions: {retrieved_entries} ({emotion_counts})\\n\"\n",
    "        f\"Generate a meaningful reflection on the user's emotions and trends.\"\n",
    "    )\n",
    "    \n",
    "    reflection = llm(summary_prompt, max_length=100, truncation=True)[0]['generated_text']\n",
    "    return reflection\n",
    "\n",
    "# Perform Sentiment Analysis with Enhanced RAG\n",
    "report = \"\\U0001F4DC *Journal Sentiment Analysis Report* \\U0001F4DC\\n\" + \"=\" * 50 + \"\\n\"\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    try:\n",
    "        print(f\"\\n---------------------------------------\\n\")\n",
    "        print(f\"Entry: {row['cleaned_text']}\")  \n",
    "\n",
    "        similar_entries_texts = retrieve_similar_entries(row['cleaned_text'])\n",
    "        print(f\"‚úÖ Retrieved {len(similar_entries_texts)} similar entries\")  \n",
    "\n",
    "        current_emotion = analyze_sentiment(row['cleaned_text'])  \n",
    "        print(f\"üìä Emotion (Current Entry): {current_emotion}\")  \n",
    "\n",
    "        ai_reflection = generate_reflection(row['cleaned_text'], similar_entries_texts)\n",
    "        print(f\"üß† AI Reflection: {ai_reflection}\")\n",
    "\n",
    "        report += f\"\\U0001F4C5 *Date:* {row['date']}\\n\"\n",
    "        report += f\"‚úç *Entry:* {row['cleaned_text']}\\n\"\n",
    "        report += f\"\\U0001F4CA *Emotion (Current Entry):* {current_emotion}\\n\"\n",
    "        report += f\"\\U0001F50E *Similar Entries Retrieved:* {len(similar_entries_texts)}\\n\"\n",
    "        report += f\"üß† *AI Reflection:* {ai_reflection}\\n\"\n",
    "        report += \"-\" * 50 + \"\\n\"\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing entry {index}: {e}\")\n",
    "\n",
    "# Save Report to File\n",
    "with open(\"sentiment_analysis_report.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(report)\n",
    "\n",
    "print(report)\n",
    "print(\"‚úÖ Sentiment analysis report with RAG and AI-generated reflections successfully generated!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c922e6e-4fde-4903-9fc5-90cf78483c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "# Load Journal Data\n",
    "df = pd.read_csv(r'C:\\Users\\DELL\\OneDrive - UPES\\Desktop\\IIT Kanpur\\data\\data.csv')\n",
    "print(f\"‚úÖ Loaded {len(df)} journal entries.\")\n",
    "\n",
    "if df.empty:\n",
    "    print(\"‚ö† DataFrame is empty. Exiting program.\")\n",
    "    exit()\n",
    "\n",
    "df['date'] = pd.date_range(start='2021-02-12', periods=len(df), freq='D')\n",
    "\n",
    "# Load Models\n",
    "sentiment_pipeline = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\")\n",
    "print(\"‚úÖ Sentiment Analysis model loaded successfully!\")\n",
    "\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "print(\"‚úÖ Sentence Transformer model loaded successfully!\")\n",
    "\n",
    "llm = pipeline(\"text2text-generation\", model=\"google/flan-t5-large\")\n",
    "print(\"‚úÖ Text Generation model (FLAN-T5) loaded successfully!\")\n",
    "\n",
    "\n",
    "# Clean Text Function\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', str(text))\n",
    "    return text.lower().strip()\n",
    "\n",
    "df['cleaned_text'] = df['Answer'].fillna(\"\").apply(clean_text)\n",
    "\n",
    "# Create Embeddings and Vector Store\n",
    "embeddings = embedding_model.encode(df['cleaned_text'].tolist(), convert_to_numpy=True)\n",
    "dimension = embeddings.shape[1]\n",
    "faiss_index = faiss.IndexFlatL2(dimension)\n",
    "\n",
    "if len(embeddings) > 0:\n",
    "    faiss_index.add(np.array(embeddings, dtype=np.float32))\n",
    "    print(\"‚úÖ FAISS index populated successfully!\")\n",
    "else:\n",
    "    print(\"‚ö† No embeddings generated. Check input data.\")\n",
    "    exit()\n",
    "\n",
    "# Retrieve Similar Entries\n",
    "def retrieve_similar_entries(query, top_k=3):\n",
    "    if faiss_index.ntotal == 0:\n",
    "        print(\"‚ö† FAISS index is empty! No retrieval possible.\")\n",
    "        return []\n",
    "    \n",
    "    query_embedding = embedding_model.encode([query], convert_to_numpy=True)\n",
    "    distances, indices = faiss_index.search(query_embedding.astype(np.float32), top_k)\n",
    "    \n",
    "    return df.iloc[indices[0]]['cleaned_text'].tolist() if len(indices) > 0 else []\n",
    "\n",
    "# Analyze Sentiment\n",
    "def analyze_sentiment(entry):\n",
    "    return sentiment_pipeline(entry)[0]['label']\n",
    "\n",
    "# Generate AI Reflection\n",
    "def generate_reflection(current_entry, retrieved_entries):\n",
    "    current_emotion = analyze_sentiment(current_entry)\n",
    "    past_emotions = [analyze_sentiment(entry) for entry in retrieved_entries]\n",
    "    \n",
    "    emotion_counts = {emotion: past_emotions.count(emotion) for emotion in set(past_emotions)}\n",
    "    dominant_emotion = max(emotion_counts, key=emotion_counts.get, default=\"neutral\")\n",
    "    \n",
    "    # Construct prompt for text generation\n",
    "    prompt = (\n",
    "        f\"User's journal entry: {current_entry}\\n\"\n",
    "        f\"Past similar entries show emotions: {emotion_counts}\\n\"\n",
    "        f\"Based on these, generate a deep and insightful reflection about the user's emotional patterns and potential future trends.\"\n",
    "    )\n",
    "    \n",
    "    # Generate reflection (without summarization constraints)\n",
    "    reflection = llm(prompt, max_new_tokens=150, do_sample=True, temperature=0.5)[0]['generated_text']\n",
    "    \n",
    "    print(reflection)  # Debugging print\n",
    "    return reflection  # Moved inside the function\n",
    "\n",
    "\n",
    "# Perform Sentiment Analysis with Enhanced RAG\n",
    "report = \"\\U0001F4DC *Journal Sentiment Analysis Report* \\U0001F4DC\\n\" + \"=\" * 50 + \"\\n\"\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    try:\n",
    "        print(f\"\\n---------------------------------------\\n\")\n",
    "        print(f\"Entry: {row['cleaned_text']}\")  \n",
    "\n",
    "        similar_entries_texts = retrieve_similar_entries(row['cleaned_text'])\n",
    "        print(f\"‚úÖ Retrieved {len(similar_entries_texts)} similar entries\")  \n",
    "\n",
    "        current_emotion = analyze_sentiment(row['cleaned_text'])  \n",
    "        print(f\"üìä Emotion (Current Entry): {current_emotion}\")  \n",
    "\n",
    "        ai_reflection = generate_reflection(row['cleaned_text'], similar_entries_texts)\n",
    "        print(f\"üß† AI Reflection: {ai_reflection}\")\n",
    "\n",
    "        report += f\"\\U0001F4C5 *Date:* {row['date']}\\n\"\n",
    "        report += f\"‚úç *Entry:* {row['cleaned_text']}\\n\"\n",
    "        report += f\"\\U0001F4CA *Emotion (Current Entry):* {current_emotion}\\n\"\n",
    "        report += f\"\\U0001F50E *Similar Entries Retrieved:* {len(similar_entries_texts)}\\n\"\n",
    "        report += f\"üß† *AI Reflection:* {ai_reflection}\\n\"\n",
    "        report += \"-\" * 50 + \"\\n\"\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing entry {index}: {e}\")\n",
    "\n",
    "# Save Report to File\n",
    "with open(\"sentiment_analysis_report.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(report)\n",
    "\n",
    "print(report)\n",
    "print(\"‚úÖ Sentiment analysis report with RAG and AI-generated reflections successfully generated!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a468b737-dbe2-4780-8a4b-1ed44e5b79be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
